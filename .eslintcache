[{"/Users/jonasbarsten/Documents/React/react-audio-mixer/src/reportWebVitals.js":"1","/Users/jonasbarsten/Documents/React/react-audio-mixer/src/App.js":"2","/Users/jonasbarsten/Documents/React/react-audio-mixer/src/index.js":"3","/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/Controls.js":"4","/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/Clock.js":"5","/Users/jonasbarsten/Documents/React/react-audio-mixer/src/utils.js":"6","/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/AudioAnalyser.js":"7","/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/AudioVisualiser.js":"8","/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/Fader.js":"9","/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/Meter.js":"10","/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/Panner.js":"11","/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/Channel.js":"12","/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/Track.js":"13","/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/Mixer.js":"14","/Users/jonasbarsten/Documents/React/react-audio-mixer/src/context/Audio.js":"15","/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/Home.js":"16","/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/Vu.js":"17","/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/TestComponent.js":"18","/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/Loader.js":"19","/Users/dev/Documents/stokkmaur/react-audio-mixer/src/index.js":"20","/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/TestComponent.js":"21","/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/Mixer.js":"22","/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/Track.js":"23","/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/Clock.js":"24","/Users/dev/Documents/stokkmaur/react-audio-mixer/src/utils.js":"25","/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/Panner.js":"26","/Users/dev/Documents/stokkmaur/react-audio-mixer/src/context/Audio.js":"27","/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/Controls.js":"28","/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/Fader.js":"29","/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/Loader.js":"30","/Users/dev/Documents/stokkmaur/react-audio-mixer/src/App.js":"31","/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/Channel.js":"32","/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/Vu.js":"33","/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/Meter.js":"34","/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/Home.js":"35","/Users/dev/Documents/stokkmaur/react-audio-mixer/src/libs/createPlaybackTrack.js":"36","/Users/dev/Documents/stokkmaur/react-audio-mixer/src/libs/audio.js":"37","/Users/dev/Documents/stokkmaur/react-audio-mixer/src/libs/createMasterTrack.js":"38","/Users/dev/Documents/stokkmaur/react-audio-mixer/src/reportWebVitals.js":"39","/Users/dev/Documents/stokkmaur/react-audio-mixer/src/libs/createInputTrack.js":"40","/Users/dev/Documents/stokkmaur/react-audio-mixer/src/hooks/useQueryParams.js":"41","/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/Header.js":"42","/Users/dev/Documents/stokkmaur/react-audio-mixer/src/libs/audio-export.js":"43","/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/MeterTest.js":"44"},{"size":362,"mtime":1611525355760,"results":"45","hashOfConfig":"46"},{"size":832,"mtime":1612098203818,"results":"47","hashOfConfig":"46"},{"size":500,"mtime":1612028630362,"results":"48","hashOfConfig":"46"},{"size":1346,"mtime":1615216446646,"results":"49","hashOfConfig":"46"},{"size":1212,"mtime":1611543945032,"results":"50","hashOfConfig":"46"},{"size":4068,"mtime":1612034640959,"results":"51","hashOfConfig":"46"},{"size":1101,"mtime":1611544801634,"results":"52","hashOfConfig":"46"},{"size":1111,"mtime":1611545277878,"results":"53","hashOfConfig":"46"},{"size":1186,"mtime":1612106653056,"results":"54","hashOfConfig":"46"},{"size":774,"mtime":1615213220080,"results":"55","hashOfConfig":"46"},{"size":2619,"mtime":1615211064937,"results":"56","hashOfConfig":"46"},{"size":1491,"mtime":1615218358077,"results":"57","hashOfConfig":"46"},{"size":273,"mtime":1612098192538,"results":"58","hashOfConfig":"46"},{"size":784,"mtime":1615219294520,"results":"59","hashOfConfig":"46"},{"size":10618,"mtime":1615220656495,"results":"60","hashOfConfig":"46"},{"size":1295,"mtime":1612106706052,"results":"61","hashOfConfig":"46"},{"size":2007,"mtime":1612096689887,"results":"62","hashOfConfig":"46"},{"size":1690,"mtime":1612091610273,"results":"63","hashOfConfig":"46"},{"size":211,"mtime":1612019178648,"results":"64","hashOfConfig":"46"},{"size":500,"mtime":1615484824432,"results":"65","hashOfConfig":"66"},{"size":1690,"mtime":1615287088684,"results":"67","hashOfConfig":"66"},{"size":832,"mtime":1615834824495,"results":"68","hashOfConfig":"66"},{"size":446,"mtime":1615834696261,"results":"69","hashOfConfig":"66"},{"size":1378,"mtime":1615485631635,"results":"70","hashOfConfig":"66"},{"size":4068,"mtime":1615287088692,"results":"71","hashOfConfig":"66"},{"size":2790,"mtime":1615819705890,"results":"72","hashOfConfig":"66"},{"size":9694,"mtime":1615836543104,"results":"73","hashOfConfig":"66"},{"size":1915,"mtime":1615805722860,"results":"74","hashOfConfig":"66"},{"size":1195,"mtime":1615833941512,"results":"75","hashOfConfig":"66"},{"size":294,"mtime":1615823579670,"results":"76","hashOfConfig":"66"},{"size":647,"mtime":1615556512237,"results":"77","hashOfConfig":"66"},{"size":2188,"mtime":1615836347376,"results":"78","hashOfConfig":"66"},{"size":2227,"mtime":1615832204950,"results":"79","hashOfConfig":"66"},{"size":751,"mtime":1615834674492,"results":"80","hashOfConfig":"66"},{"size":205,"mtime":1615834756038,"results":"81","hashOfConfig":"66"},{"size":2344,"mtime":1615836618238,"results":"82","hashOfConfig":"66"},{"size":7544,"mtime":1615814385743,"results":"83","hashOfConfig":"66"},{"size":1038,"mtime":1615398638405,"results":"84","hashOfConfig":"66"},{"size":362,"mtime":1615287088690,"results":"85","hashOfConfig":"66"},{"size":1871,"mtime":1615399655451,"results":"86","hashOfConfig":"66"},{"size":1030,"mtime":1615553755197,"results":"87","hashOfConfig":"66"},{"size":287,"mtime":1615800081434,"results":"88","hashOfConfig":"66"},{"size":7212,"mtime":1615823526393,"results":"89","hashOfConfig":"66"},{"size":2750,"mtime":1615833769109,"results":"90","hashOfConfig":"66"},{"filePath":"91","messages":"92","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"93"},"6ni04",{"filePath":"94","messages":"95","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"96","usedDeprecatedRules":"97"},{"filePath":"98","messages":"99","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"100"},{"filePath":"101","messages":"102","errorCount":0,"warningCount":3,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"103","messages":"104","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"100"},{"filePath":"105","messages":"106","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"107"},{"filePath":"108","messages":"109","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"110"},{"filePath":"111","messages":"112","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"113"},{"filePath":"114","messages":"115","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"93"},{"filePath":"116","messages":"117","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"118","messages":"119","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"120","messages":"121","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"122","messages":"123","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"100"},{"filePath":"124","messages":"125","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"126","messages":"127","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"128","messages":"129","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"93"},{"filePath":"130","messages":"131","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"132","usedDeprecatedRules":"133"},{"filePath":"134","messages":"135","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"136","usedDeprecatedRules":"137"},{"filePath":"138","messages":"139","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"140","messages":"141","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"142"},"xqqwo4",{"filePath":"143","messages":"144","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"145","messages":"146","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"147","messages":"148","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"149","messages":"150","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"151"},{"filePath":"152","messages":"153","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"154"},{"filePath":"155","messages":"156","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"157","messages":"158","errorCount":0,"warningCount":4,"fixableErrorCount":0,"fixableWarningCount":0,"source":"159"},{"filePath":"160","messages":"161","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"154"},{"filePath":"162","messages":"163","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"164","messages":"165","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"166","messages":"167","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"154"},{"filePath":"168","messages":"169","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"170","messages":"171","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},{"filePath":"172","messages":"173","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"174","messages":"175","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"176","messages":"177","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"178","messages":"179","errorCount":0,"warningCount":1,"fixableErrorCount":0,"fixableWarningCount":0,"source":"180","usedDeprecatedRules":"181"},{"filePath":"182","messages":"183","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"142"},{"filePath":"184","messages":"185","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"181"},{"filePath":"186","messages":"187","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"181"},{"filePath":"188","messages":"189","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"190"},{"filePath":"191","messages":"192","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0,"usedDeprecatedRules":"154"},{"filePath":"193","messages":"194","errorCount":0,"warningCount":0,"fixableErrorCount":0,"fixableWarningCount":0},{"filePath":"195","messages":"196","errorCount":1,"warningCount":8,"fixableErrorCount":0,"fixableWarningCount":0,"source":null},"/Users/jonasbarsten/Documents/React/react-audio-mixer/src/reportWebVitals.js",[],["197","198"],"/Users/jonasbarsten/Documents/React/react-audio-mixer/src/App.js",["199"],"import React from \"react\";\nimport Home from \"./components/Home\";\nimport AudioContextProvider from \"./context/Audio\";\n\nimport TestComponent from \"./components/TestComponent\";\n\nimport \"./fonts/digital-7.eot\";\nimport \"./fonts/digital-7.svg\";\nimport \"./fonts/digital-7.ttf\";\nimport \"./fonts/digital-7.woff\";\n\nimport \"./stylesheets/normalize.css\";\nimport \"./stylesheets/normalize-edit.css\";\nimport \"./stylesheets/fonts.css\";\nimport \"./stylesheets/loader.css\";\nimport \"./stylesheets/main.css\";\n\nconst App = () => {\n  return (\n    <>\n      <AudioContextProvider>\n        <div className=\"App\">\n          <header>\n            <h1>Stokkmaur</h1>\n          </header>\n          <Home />\n          {/* <TestComponent /> */}\n        </div>\n      </AudioContextProvider>\n      <div id=\"audio-container\"></div>\n    </>\n  );\n};\n\nexport default App;\n",["200","201"],"/Users/jonasbarsten/Documents/React/react-audio-mixer/src/index.js",[],["202","203"],"/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/Controls.js",["204","205","206"],"/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/Clock.js",[],"/Users/jonasbarsten/Documents/React/react-audio-mixer/src/utils.js",[],["207","208"],"/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/AudioAnalyser.js",[],["209","210"],"/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/AudioVisualiser.js",[],["211","212"],"/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/Fader.js",[],"/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/Meter.js",[],"/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/Panner.js",[],"/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/Channel.js",[],"/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/Track.js",[],"/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/Mixer.js",[],"/Users/jonasbarsten/Documents/React/react-audio-mixer/src/context/Audio.js",["213"],"/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/Home.js",[],"/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/Vu.js",["214"],"import React, { useContext, useState, useRef, useEffect } from \"react\";\nimport { AudioContext } from \"../context/Audio\";\nimport { dBFSCalc, scale } from \"../utils\";\n\nconst nodeMap = {\n  left: \"analyserNodeL\",\n  right: \"analyserNodeR\",\n};\n\nconst Vu = (props) => {\n  const analyserNodeName = nodeMap[props.channel];\n  const [deg, setDeg] = useState(0);\n  const animationRef = useRef(null);\n  const audioContext = useContext(AudioContext);\n  const masterTrack = audioContext.getMasterTrack();\n  const bufferLength = masterTrack[analyserNodeName].fftSize;\n  const animationData = useRef(new Uint8Array(bufferLength));\n  let vuData = [];\n\n  const animate = () => {\n    const len = animationData.current.length;\n    let newDbfs = new Array(len);\n\n    masterTrack[analyserNodeName].getByteTimeDomainData(animationData.current);\n\n    for (let i = 0; i < len; ++i) {\n      newDbfs[i] = (animationData.current[i] * 2) / 255 - 1;\n    }\n\n    // TODO: set to -192 if not playing, could not get playing state from context here, it was always false\n    newDbfs = dBFSCalc(newDbfs);\n    let newDeg = Math.max(-20, scale(newDbfs + 20, -20, 0, 0, 60));\n\n    vuData.unshift(newDeg);\n\n    if (vuData.length >= 18) {\n      vuData.length = 18;\n    }\n\n    newDeg =\n      vuData.reduce((sum, curr) => {\n        return sum + curr;\n      }, 0) / vuData.length;\n\n    setDeg(newDeg);\n\n    animationRef.current = requestAnimationFrame(animate);\n  };\n\n  useEffect(() => {\n    animationRef.current = requestAnimationFrame(animate);\n    return () => cancelAnimationFrame(animationRef.current);\n  }, []);\n\n  return (\n    <div className=\"vu\">\n      <div className=\"mask\">\n        <div\n          className={`needle ${props.channel}`}\n          style={{\n            WebkitTransform: `rotate(${deg}deg)`,\n            MozTransform: `rotate(${deg}deg)`,\n            transform: `rotate(${deg}deg)`,\n          }}\n        ></div>\n      </div>\n      <p className=\"vu-label\">{props.channel[0].toUpperCase()}</p>\n    </div>\n  );\n};\n\nexport default Vu;\n",["215","216"],"/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/TestComponent.js",["217"],"import React, { useContext, useRef, useEffect } from \"react\";\n\nimport { AudioContext } from \"../context/Audio\";\n\nconst TestComponent = () => {\n  const audioContext = useContext(AudioContext);\n  const canvasRef = useRef(null);\n  const animationRef = useRef(null);\n  const masterTrack = audioContext.getMasterTrack();\n  const bufferLength = masterTrack.analyserNodeL.fftSize;\n  const animationData = useRef(new Uint8Array(bufferLength));\n\n  // TODO: start / stop animation with audio start / stop if that is necessary for performance\n  const animate = () => {\n    const width = 200;\n    const height = 200;\n    const canvas = canvasRef.current;\n    const canvasCtx = canvas.getContext(\"2d\");\n\n    masterTrack.analyserNodeL.getByteTimeDomainData(animationData.current);\n\n    canvasCtx.fillStyle = \"rgb(200, 200, 200)\";\n    canvasCtx.fillRect(0, 0, width, height);\n\n    canvasCtx.lineWidth = 2;\n    canvasCtx.strokeStyle = \"rgb(0, 0, 0)\";\n\n    const sliceWidth = (width * 1.0) / bufferLength;\n    let x = 0;\n\n    canvasCtx.beginPath();\n    for (var i = 0; i < bufferLength; i++) {\n      const v = animationData.current[i] / 128.0;\n      const y = (v * height) / 2;\n\n      if (i === 0) canvasCtx.moveTo(x, y);\n      else canvasCtx.lineTo(x, y);\n\n      x += sliceWidth;\n    }\n\n    canvasCtx.lineTo(width, height / 2);\n    canvasCtx.stroke();\n    animationRef.current = requestAnimationFrame(animate);\n  };\n\n  useEffect(() => {\n    animationRef.current = requestAnimationFrame(animate);\n    return () => cancelAnimationFrame(animationRef.current);\n  }, []);\n\n  return (\n    <div style={{ color: \"white\" }}>\n      <canvas ref={canvasRef}></canvas>\n    </div>\n  );\n};\n\nexport default TestComponent;\n",["218","219"],"/Users/jonasbarsten/Documents/React/react-audio-mixer/src/components/Loader.js",[],"/Users/dev/Documents/stokkmaur/react-audio-mixer/src/index.js",[],["220","221"],"/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/TestComponent.js",["222"],"/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/Mixer.js",[],"/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/Track.js",[],"/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/Clock.js",[],["223","224"],"/Users/dev/Documents/stokkmaur/react-audio-mixer/src/utils.js",[],["225","226"],"/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/Panner.js",[],"/Users/dev/Documents/stokkmaur/react-audio-mixer/src/context/Audio.js",["227","228","229","230"],"// buffer source -> mute -> gain -> pan -> (track analyser) -> master gain -> splitter -> (master analyser x 2 VU) -> merger -> dest\nimport React, { useState, useEffect, useRef } from \"react\";\n\n// Hooks\nimport useQueryParam from \"../hooks/useQueryParams\";\n\n// Libs\nimport createMasterTrack from \"../libs/createMasterTrack\";\nimport createPlaybackTrack from \"../libs/createPlaybackTrack\";\nimport createInputTrack from \"../libs/createInputTrack\";\nimport { createAsyncBufferSource } from \"../libs/audio\";\nimport { offlineRender } from \"../libs/audio-export\";\n\n// Components\nimport Loader from \"../components/Loader\";\n\n// Config\nimport config from \"../config.json\";\n\nlet audioCtx = new (window.AudioContext || window.webkitAudioContext)();\n\nif (!audioCtx.createGain) audioCtx.createGain = audioCtx.createGainNode;\nif (!audioCtx.createDelay) audioCtx.createDelay = audioCtx.createDelayNode;\nif (!audioCtx.createScriptProcessor)\n  audioCtx.createScriptProcessor = audioCtx.createJavaScriptNode;\n\nexport const AudioContext = React.createContext();\n\nconst AudioContextProvider = ({ children }) => {\n  // Refs\n  const currentTime = useRef(0);\n  const startedAt = useRef(0);\n  const pausedAt = useRef(0);\n  const recording = useRef(false);\n  const recordedChunks = useRef([]);\n\n  // State\n  const [song, setSong] = useQueryParam(\"song\", \"phoenix\");\n  const [masterTrack, setMasterTrack] = useState(null);\n  const [tracks, setTracks] = useState(null);\n  const [playing, setPlaying] = useState(false);\n  const [mutedTracks, setMutedTracks] = useState([]);\n  const [loadProgress, setLoadProgress] = useState(0);\n  const [exportProgress, setExportProgress] = useState(0);\n  const [exportProgressStage, setExportProgressStage] = useState(\"\");\n\n  // Use effect (except keydown)\n  useEffect(() => {\n    const onLoad = async () => {\n      const masterNode = createMasterNode();\n      const playbackTracks = await loadAudio(masterNode);\n      // const inputTracks = await createInputNode(masterNode);\n      const inputTracks = [];\n      setTracks([...playbackTracks, ...inputTracks]);\n    };\n\n    onLoad();\n\n    return () => {\n      audioCtx && audioCtx.close();\n      tracks &&\n        tracks.forEach((track) => {\n          if (track.recorder) {\n            track.recorder.removeEventListener(\n              \"dataavailable\",\n              handleRecordedData\n            );\n          }\n        });\n    };\n  }, []);\n\n  // Functions\n  const createMasterNode = () => {\n    const masterNode = createMasterTrack(audioCtx);\n    setMasterTrack(masterNode);\n    return masterNode;\n  };\n\n  const loadAudio = async (masterNode) => {\n    let newTracks = [];\n    let count = 1;\n\n    for (const track of config.songs[song].tracks) {\n      const progress = count / config.songs[song].tracks.length;\n      setLoadProgress(progress);\n      count++;\n      if (!track) {\n        return;\n      }\n      const newTrack = await createPlaybackTrack(\n        audioCtx,\n        masterNode,\n        song,\n        track\n      );\n      newTracks.push(newTrack);\n    }\n    return newTracks;\n    // createInputNode(masterNode, newTracks);\n  };\n\n  const createInputNode = async (masterNode) => {\n    const newInputTrack = await createInputTrack(audioCtx, masterNode);\n    setMutedTracks([...mutedTracks, newInputTrack.id]);\n\n    newInputTrack.recorder.addEventListener(\n      \"dataavailable\",\n      handleRecordedData\n    );\n\n    return [newInputTrack];\n  };\n\n  const getCurrentTime = () => {\n    if (pausedAt.current) {\n      currentTime.current = pausedAt.current;\n      return pausedAt.current;\n    }\n    currentTime.current = audioCtx.currentTime - startedAt.current;\n    return audioCtx.currentTime - startedAt.current;\n  };\n\n  const exportAudio = () => {\n    let allBuffers = [];\n    tracks.forEach((track) => {\n      allBuffers.push(track.buffer.buffer);\n    });\n\n    const progress = (data) => {\n      setExportProgress(data);\n    };\n\n    const progressStage = (data) => {\n      setExportProgressStage(data);\n    };\n\n    offlineRender(tracks, config.songs[song].duration, progress, progressStage);\n  };\n\n  const recordStart = (track) => {\n    backToStart();\n    recording.current = true;\n    track.recorder.startTime = audioCtx.currentTime;\n    track.recorder.start();\n  };\n\n  const recordStop = async (track) => {\n    recording.current = false;\n    track.recorder.stop();\n\n    setTimeout(async () => {\n      const blob = new Blob(recordedChunks.current, {\n        type: \"audio/ogg; codecs=opus\",\n      });\n      const audioArrayBuffer = await blob.arrayBuffer();\n      const decodedAudio = await createAsyncBufferSource(\n        audioCtx,\n        audioArrayBuffer\n      );\n      const bufferSource = audioCtx.createBufferSource();\n      bufferSource.buffer = decodedAudio;\n\n      track.buffer = bufferSource;\n      track.type = \"playback\";\n      playBufferNode(track, 0);\n      pauseAll();\n\n      recordedChunks.current = [];\n    }, 1000);\n  };\n\n  const handleRecordedData = async (e) => {\n    const allChunks = [...recordedChunks.current, e.data];\n    recordedChunks.current = allChunks;\n  };\n\n  const playBufferNode = (track, offset) => {\n    const bufferSource = audioCtx.createBufferSource();\n    bufferSource.buffer = track.decodedAudio;\n    track.buffer = bufferSource;\n    track.buffer.connect(track.muteNode);\n    track.buffer.start(0, offset);\n  };\n\n  const playAll = () => {\n    if (audioCtx.state === \"suspended\") {\n      audioCtx.resume();\n    }\n    const offset = pausedAt.current;\n\n    tracks.forEach((track) => {\n      if (track.type === \"playback\") {\n        playBufferNode(track, offset);\n      }\n    });\n    startedAt.current = audioCtx.currentTime - offset;\n    pausedAt.current = 0;\n    setPlaying(true);\n  };\n\n  const pauseAll = () => {\n    const elapsed = audioCtx.currentTime - startedAt.current;\n    tracks.forEach((track) => {\n      if (track.type === \"playback\") {\n        track.buffer.stop();\n      }\n    });\n    pausedAt.current = elapsed;\n    setPlaying(false);\n  };\n\n  const togglePlayAll = () => {\n    if (!playing) {\n      playAll();\n    } else {\n      pauseAll();\n    }\n  };\n\n  useEffect(() => {\n    const handleKeyDown = (event) => {\n      if (event.keyCode === 32) {\n        togglePlayAll();\n      }\n    };\n    window.addEventListener(\"keydown\", handleKeyDown);\n    return () => {\n      window.removeEventListener(\"keydown\", handleKeyDown);\n    };\n  }, [togglePlayAll]);\n\n  // TODO: implement with buffer\n  const rewind = () => {\n    let newTime = currentTime.current - 5; // One second\n    if (newTime <= 0) {\n      newTime = 0;\n    }\n    tracks.forEach((track) => {\n      if (track.type === \"playback\") {\n        track.elem.currentTime = newTime;\n      }\n    });\n    currentTime.current = newTime;\n  };\n\n  // TODO: implement with buffer\n  const forward = () => {\n    let newTime = currentTime.current + 5; // One second\n    const maxTime = tracks[0].elem.duration;\n    if (newTime >= maxTime - 1) {\n      newTime = maxTime - 1;\n    }\n    tracks.forEach((track) => {\n      if (track.type === \"playback\") {\n        track.elem.currentTime = newTime;\n      }\n    });\n    currentTime.current = newTime;\n  };\n\n  const backToStart = () => {\n    pausedAt.current = 0;\n    startedAt.current = 0;\n    tracks.forEach((track) => {\n      if (track.type === \"playback\") {\n        track.buffer.stop(0);\n      }\n    });\n    if (playing) {\n      playAll();\n    }\n  };\n\n  const setMasterGain = (gain) => {\n    masterTrack.gainNode.gain.value = gain;\n  };\n\n  const toggleSolo = (id, solo) => {\n    if (solo) {\n      tracks.forEach((track) => {\n        if (track.id === id) {\n          track.solo = true;\n          return;\n        }\n        track.muteNode.gain.value = 0;\n        track.solo = false;\n        track.mute = true;\n      });\n    } else {\n      tracks.forEach((track) => {\n        // Keep muted tracks muted after un-solo\n        if (mutedTracks.indexOf(track.id) !== -1) {\n          return;\n        } else {\n          track.muteNode.gain.value = 1;\n          track.solo = false;\n        }\n      });\n    }\n  };\n\n  const toggleMute = (id, mute) => {\n    // TODO: do this more efficently\n    tracks.forEach((track) => {\n      if (track.id === id) {\n        if (mute) {\n          track.muteNode.gain.value = 0;\n          setMutedTracks([...mutedTracks, track.id]);\n        }\n\n        if (!mute) {\n          track.muteNode.gain.value = 1;\n          const newMutedTracks = [...mutedTracks].filter((trackId) => {\n            return trackId !== id;\n          });\n          setMutedTracks(newMutedTracks);\n        }\n      }\n    });\n  };\n\n  const toggleDelay = (track, delay) => {\n    if (delay) {\n      track.pannerNode\n        .connect(track.convolverNode)\n        .connect(masterTrack.gainNode);\n    } else {\n      track.pannerNode.connect(masterTrack.gainNode);\n      track.convolverNode.disconnect(masterTrack.gainNode);\n    }\n  };\n\n  // TODO: export could be done in parallel with mixing ...\n\n  return (\n    <AudioContext.Provider\n      value={{\n        togglePlayAll,\n        playing: () => playing,\n        getTracks: () => tracks,\n        getMasterTrack: () => masterTrack,\n        setMasterGain,\n        getAudioContext: () => audioCtx,\n        toggleSolo,\n        toggleMute,\n        backToStart,\n        rewind,\n        forward,\n        exportAudio,\n        recordStart,\n        recordStop,\n        getCurrentTime,\n        song: () => song,\n        toggleDelay,\n      }}\n    >\n      {exportProgress ? (\n        <Loader progress={exportProgress} text={exportProgressStage} />\n      ) : !tracks || tracks.length < 1 ? (\n        <Loader progress={loadProgress} text=\"Loading Audio Assets...\" />\n      ) : (\n        children\n      )}\n    </AudioContext.Provider>\n  );\n};\n\nexport default AudioContextProvider;\n","/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/Controls.js",[],"/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/Fader.js",[],"/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/Loader.js",[],"/Users/dev/Documents/stokkmaur/react-audio-mixer/src/App.js",[],"/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/Channel.js",[],"/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/Vu.js",["231"],"/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/Meter.js",[],"/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/Home.js",[],"/Users/dev/Documents/stokkmaur/react-audio-mixer/src/libs/createPlaybackTrack.js",[],"/Users/dev/Documents/stokkmaur/react-audio-mixer/src/libs/audio.js",["232"],"import lamejs from \"lamejs\";\n\nfunction writeString(view, offset, string) {\n  for (var i = 0; i < string.length; i++) {\n    view.setUint8(offset + i, string.charCodeAt(i));\n  }\n}\n\nfunction floatTo16BitPCM(output, offset, input) {\n  for (var i = 0; i < input.length; i++, offset += 2) {\n    var s = Math.max(-1, Math.min(1, input[i]));\n    output.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7fff, true);\n  }\n}\n\nfunction mergeBuffers(buffers, recLength) {\n  console.log(buffers);\n  console.log(recLength);\n  var result = new Float32Array(recLength);\n  console.log(result);\n  var offset = 0;\n  for (var i = 0; i < buffers.length; i++) {\n    result.set(buffers[i], offset);\n    offset += buffers[i].length;\n  }\n  return result;\n}\n\nfunction interleave(inputL, inputR) {\n  var length = inputL.length + inputR.length;\n  // var result = new Float32Array(length);\n  var result = new Int16Array(length);\n\n  var index = 0,\n    inputIndex = 0;\n\n  while (index < length) {\n    result[index++] = inputL[inputIndex];\n    result[index++] = inputR[inputIndex];\n    inputIndex++;\n  }\n  return result;\n}\n\nfunction encodeWAV(samples, numChannels, sampleRate) {\n  var buffer = new ArrayBuffer(44 + samples.length * 2);\n  var view = new DataView(buffer);\n\n  /* RIFF identifier */\n  writeString(view, 0, \"RIFF\");\n  /* RIFF chunk length */\n  view.setUint32(4, 36 + samples.length * 2, true);\n  /* RIFF type */\n  writeString(view, 8, \"WAVE\");\n  /* format chunk identifier */\n  writeString(view, 12, \"fmt \");\n  /* format chunk length */\n  view.setUint32(16, 16, true);\n  /* sample format (raw) */\n  view.setUint16(20, 1, true);\n  /* channel count */\n  view.setUint16(22, numChannels, true);\n  /* sample rate */\n  view.setUint32(24, sampleRate, true);\n  /* byte rate (sample rate * block align) */\n  view.setUint32(28, sampleRate * 4, true);\n  /* block align (channel count * bytes per sample) */\n  view.setUint16(32, numChannels * 2, true);\n  /* bits per sample */\n  view.setUint16(34, 16, true);\n  /* data chunk identifier */\n  writeString(view, 36, \"data\");\n  /* data chunk length */\n  view.setUint32(40, samples.length * 2, true);\n\n  floatTo16BitPCM(view, 44, samples);\n\n  return view;\n}\n\nexport function createAsyncBufferSource(audioCtx, arrayBuffer) {\n  return new Promise((resolve, reject) => {\n    audioCtx.decodeAudioData(\n      arrayBuffer,\n      (buffer) => {\n        resolve(buffer);\n      },\n      (e) => {\n        e = reject;\n      }\n    );\n  });\n}\n\nexport function offsetBuffer(audioCtx, recordingBuffer, before, after) {\n  console.log(\"player.offsetBuffer\", recordingBuffer, before, after);\n  var i = 0,\n    channel = 0,\n    channelTotal = 2,\n    num = 0,\n    audioBuffer = audioCtx.createBuffer(\n      channelTotal,\n      before + recordingBuffer[0].length + after,\n      audioCtx.sampleRate\n    ),\n    buffer = null;\n  for (channel = 0; channel < channelTotal; channel += 1) {\n    buffer = audioBuffer.getChannelData(channel);\n    for (i = 0; i < before; i += 1) {\n      buffer[num] = 0;\n      num += 1;\n    }\n    for (i = 0; i < recordingBuffer[channel].length; i += 1) {\n      buffer[num] = recordingBuffer[channel][i];\n      num += 1;\n    }\n    for (i = 0; i < after; i += 1) {\n      buffer[num] = 0;\n      num += 1;\n    }\n  }\n  return audioBuffer;\n}\n\nexport function getOffset(\n  audioCtx,\n  recordingBuffer,\n  referenceBuffer,\n  offset,\n  recorder\n) {\n  let diff = recorder.startTime + offset / 1000 - referenceBuffer.startTime;\n  console.log(\"player.getOffset\", diff);\n  return {\n    before: Math.round(\n      (diff % referenceBuffer.buffer.duration) * audioCtx.sampleRate\n    ),\n    after: Math.round(\n      (referenceBuffer.buffer.duration -\n        ((diff + recordingBuffer.duration) % referenceBuffer.buffer.duration)) *\n        audioCtx.sampleRate\n    ),\n  };\n}\n\nexport function createBuffer(audioCtx, buffers, channelTotal) {\n  let channel = 0;\n  let buffer = audioCtx.createBuffer(\n    channelTotal,\n    buffers[0].length,\n    audioCtx.sampleRate\n  );\n  for (channel = 0; channel < channelTotal; channel += 1) {\n    buffer.getChannelData(channel).set(buffers[channel]);\n  }\n  return buffer;\n}\n\nexport function exportWAV(type, allBuffers, recLength, numChannels) {\n  // var buffers = [];\n  // for (var channel = 0; channel < numChannels; channel++) {\n  //   buffers.push(mergeBuffers(allBuffers[channel], recLength));\n  // }\n  let interleaved = undefined;\n  if (numChannels === 2) {\n    interleaved = interleave(allBuffers[2], allBuffers[4]);\n  } else {\n    interleaved = allBuffers[0];\n  }\n  const dataView = encodeWAV(interleaved, numChannels, 48000);\n  const audioBlob = new Blob([dataView], { type: type });\n  console.log(audioBlob);\n\n  forceDownload(audioBlob, \"my mix.wav\");\n}\n\nexport function exportMP3(allBuffers) {\n  const channels = 1; //1 for mono or 2 for stereo\n  const sampleRate = 44100; //44.1khz (normal mp3 samplerate)\n  const kbps = 128; //encode 128kbps mp3\n  const mp3encoder = new lamejs.Mp3Encoder(channels, sampleRate, kbps);\n\n  const interleaved = interleave(allBuffers[2], allBuffers[4]);\n\n  const samples = interleaved; //one second of silence (get your data from the source you have)\n  const sampleBlockSize = 1152; //can be anything but make it a multiple of 576 to make encoders life easier\n\n  var mp3Data = [];\n  for (var i = 0; i < samples.length; i += sampleBlockSize) {\n    const sampleChunk = samples.subarray(i, i + sampleBlockSize);\n    var mp3buf = mp3encoder.encodeBuffer(sampleChunk);\n    if (mp3buf.length > 0) {\n      mp3Data.push(mp3buf);\n    }\n  }\n  const d = mp3encoder.flush(); //finish writing mp3\n\n  if (d.length > 0) {\n    mp3Data.push(new Int8Array(mp3buf));\n  }\n\n  const blob = new Blob(mp3Data, { type: \"audio/mp3\" });\n  forceDownload(blob, \"test.mp3\");\n}\n\nfunction forceDownload(blob, fileName) {\n  const url = (window.URL || window.webkitURL).createObjectURL(blob);\n  const link = window.document.createElement(\"a\");\n  link.href = url;\n  link.download = fileName || \"my mix.wav\";\n  link.click();\n}\n\n// export function exportWAV(\n//   type,\n//   allBuffers,\n//   recLength,\n//   numChannels,\n//   before = 0,\n//   after = 0\n// ) {\n//   // if (!before) {\n//   //   before = 0;\n//   // }\n//   // if (!after) {\n//   //   after = 0;\n//   // }\n\n//   var channel = 0,\n//     buffers = [];\n//   for (channel = 0; channel < numChannels; channel++) {\n//     buffers.push(mergeBuffers(allBuffers[channel], recLength));\n//   }\n\n//   var i = 0,\n//     offset = 0,\n//     newbuffers = [];\n\n//   for (channel = 0; channel < numChannels; channel += 1) {\n//     offset = 0;\n//     newbuffers[channel] = new Float32Array(before + recLength + after);\n//     if (before > 0) {\n//       for (i = 0; i < before; i += 1) {\n//         newbuffers[channel].set([0], offset);\n//         offset += 1;\n//       }\n//     }\n//     newbuffers[channel].set(buffers[channel], offset);\n//     offset += buffers[channel].length;\n//     if (after > 0) {\n//       for (i = 0; i < after; i += 1) {\n//         newbuffers[channel].set([0], offset);\n//         offset += 1;\n//       }\n//     }\n//   }\n\n//   let interleaved = undefined;\n\n//   if (numChannels === 2) {\n//     interleaved = interleave(newbuffers[0], newbuffers[1]);\n//   } else {\n//     interleaved = newbuffers[0];\n//   }\n\n//   // var downsampledBuffer = downsampleBuffer(interleaved, rate);\n//   // var dataview = encodeWAV(downsampledBuffer, rate);\n//   const dataView = encodeWAV(interleaved, numChannels, 48000);\n//   var audioBlob = new Blob([dataView], { type: type });\n\n//   forceDownload(audioBlob, \"my mix.wav\");\n\n//   // this.postMessage(audioBlob);\n// }\n",["233","234"],"/Users/dev/Documents/stokkmaur/react-audio-mixer/src/libs/createMasterTrack.js",[],"/Users/dev/Documents/stokkmaur/react-audio-mixer/src/reportWebVitals.js",[],"/Users/dev/Documents/stokkmaur/react-audio-mixer/src/libs/createInputTrack.js",[],"/Users/dev/Documents/stokkmaur/react-audio-mixer/src/hooks/useQueryParams.js",[],["235","236"],"/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/Header.js",[],"/Users/dev/Documents/stokkmaur/react-audio-mixer/src/libs/audio-export.js",[],"/Users/dev/Documents/stokkmaur/react-audio-mixer/src/components/MeterTest.js",["237","238","239","240","241","242","243","244","245"],{"ruleId":"246","replacedBy":"247"},{"ruleId":"248","replacedBy":"249"},{"ruleId":"250","severity":1,"message":"251","line":5,"column":8,"nodeType":"252","messageId":"253","endLine":5,"endColumn":21},{"ruleId":"246","replacedBy":"254"},{"ruleId":"248","replacedBy":"255"},{"ruleId":"246","replacedBy":"256"},{"ruleId":"248","replacedBy":"257"},{"ruleId":"250","severity":1,"message":"258","line":1,"column":29,"nodeType":"252","messageId":"253","endLine":1,"endColumn":38},{"ruleId":"250","severity":1,"message":"259","line":1,"column":40,"nodeType":"252","messageId":"253","endLine":1,"endColumn":48},{"ruleId":"250","severity":1,"message":"260","line":5,"column":10,"nodeType":"252","messageId":"253","endLine":5,"endColumn":45},{"ruleId":"246","replacedBy":"261"},{"ruleId":"248","replacedBy":"262"},{"ruleId":"246","replacedBy":"263"},{"ruleId":"248","replacedBy":"264"},{"ruleId":"246","replacedBy":"265"},{"ruleId":"248","replacedBy":"266"},{"ruleId":"267","severity":1,"message":"268","line":64,"column":6,"nodeType":"269","endLine":64,"endColumn":8,"suggestions":"270"},{"ruleId":"267","severity":1,"message":"271","line":53,"column":6,"nodeType":"269","endLine":53,"endColumn":8,"suggestions":"272"},{"ruleId":"246","replacedBy":"273"},{"ruleId":"248","replacedBy":"274"},{"ruleId":"267","severity":1,"message":"271","line":50,"column":6,"nodeType":"269","endLine":50,"endColumn":8,"suggestions":"275"},{"ruleId":"246","replacedBy":"276"},{"ruleId":"248","replacedBy":"277"},{"ruleId":"246","replacedBy":"278"},{"ruleId":"248","replacedBy":"279"},{"ruleId":"267","severity":1,"message":"271","line":50,"column":6,"nodeType":"269","endLine":50,"endColumn":8,"suggestions":"280"},{"ruleId":"246","replacedBy":"281"},{"ruleId":"248","replacedBy":"282"},{"ruleId":"246","replacedBy":"283"},{"ruleId":"248","replacedBy":"284"},{"ruleId":"250","severity":1,"message":"285","line":38,"column":16,"nodeType":"252","messageId":"253","endLine":38,"endColumn":23},{"ruleId":"267","severity":1,"message":"286","line":71,"column":6,"nodeType":"269","endLine":71,"endColumn":8,"suggestions":"287"},{"ruleId":"250","severity":1,"message":"288","line":103,"column":9,"nodeType":"252","messageId":"253","endLine":103,"endColumn":24},{"ruleId":"267","severity":1,"message":"289","line":213,"column":9,"nodeType":"290","endLine":219,"endColumn":4,"suggestions":"291"},{"ruleId":"267","severity":1,"message":"271","line":63,"column":6,"nodeType":"269","endLine":63,"endColumn":15,"suggestions":"292"},{"ruleId":"250","severity":1,"message":"293","line":16,"column":10,"nodeType":"252","messageId":"253","endLine":16,"endColumn":22},{"ruleId":"246","replacedBy":"294"},{"ruleId":"248","replacedBy":"295"},{"ruleId":"246","replacedBy":"296"},{"ruleId":"248","replacedBy":"297"},{"ruleId":"250","severity":1,"message":"298","line":1,"column":17,"nodeType":"252","messageId":"253","endLine":1,"endColumn":27},{"ruleId":"250","severity":1,"message":"259","line":1,"column":29,"nodeType":"252","messageId":"253","endLine":1,"endColumn":37},{"ruleId":"250","severity":1,"message":"299","line":1,"column":39,"nodeType":"252","messageId":"253","endLine":1,"endColumn":45},{"ruleId":"250","severity":1,"message":"258","line":1,"column":47,"nodeType":"252","messageId":"253","endLine":1,"endColumn":56},{"ruleId":"250","severity":1,"message":"300","line":2,"column":10,"nodeType":"252","messageId":"253","endLine":2,"endColumn":22},{"ruleId":"250","severity":1,"message":"301","line":3,"column":10,"nodeType":"252","messageId":"253","endLine":3,"endColumn":18},{"ruleId":"250","severity":1,"message":"302","line":3,"column":20,"nodeType":"252","messageId":"253","endLine":3,"endColumn":25},{"ruleId":"303","severity":1,"message":"304","line":80,"column":3,"nodeType":"305","messageId":"306","endLine":80,"endColumn":24},{"ruleId":"307","severity":2,"message":"308","line":80,"column":14,"nodeType":"252","messageId":"309","endLine":80,"endColumn":18},"no-native-reassign",["310"],"no-negated-in-lhs",["311"],"no-unused-vars","'TestComponent' is defined but never used.","Identifier","unusedVar",["310"],["311"],["310"],["311"],"'useEffect' is defined but never used.","'useState' is defined but never used.","'unstable_renderSubtreeIntoContainer' is defined but never used.",["310"],["311"],["310"],["311"],["310"],["311"],"react-hooks/exhaustive-deps","React Hook useEffect has a missing dependency: 'loadAudio'. Either include it or remove the dependency array.","ArrayExpression",["312"],"React Hook useEffect has a missing dependency: 'animate'. Either include it or remove the dependency array.",["313"],["310"],["311"],["314"],["310"],["311"],["310"],["311"],["315"],["310"],["311"],["310"],["311"],"'setSong' is assigned a value but never used.","React Hook useEffect has missing dependencies: 'loadAudio' and 'tracks'. Either include them or remove the dependency array.",["316"],"'createInputNode' is assigned a value but never used.","The 'togglePlayAll' function makes the dependencies of useEffect Hook (at line 231) change on every render. To fix this, wrap the definition of 'togglePlayAll' in its own useCallback() Hook.","VariableDeclarator",["317"],["318"],"'mergeBuffers' is defined but never used.",["310"],["311"],["310"],["311"],"'useContext' is defined but never used.","'useRef' is defined but never used.","'AudioContext' is defined but never used.","'dBFSCalc' is defined but never used.","'scale' is defined but never used.","no-unreachable","Unreachable code.","ReturnStatement","unreachableCode","no-undef","'peak' is not defined.","undef","no-global-assign","no-unsafe-negation",{"desc":"319","fix":"320"},{"desc":"321","fix":"322"},{"desc":"321","fix":"323"},{"desc":"321","fix":"324"},{"desc":"325","fix":"326"},{"desc":"327","fix":"328"},{"desc":"329","fix":"330"},"Update the dependencies array to be: [loadAudio]",{"range":"331","text":"332"},"Update the dependencies array to be: [animate]",{"range":"333","text":"334"},{"range":"335","text":"334"},{"range":"336","text":"334"},"Update the dependencies array to be: [loadAudio, tracks]",{"range":"337","text":"338"},"Wrap the definition of 'togglePlayAll' in its own useCallback() Hook.",{"range":"339","text":"340"},"Update the dependencies array to be: [animate, playing]",{"range":"341","text":"342"},[2152,2154],"[loadAudio]",[1567,1569],"[animate]",[1546,1548],[1546,1548],[2390,2392],"[loadAudio, tracks]",[5979,6064],"useCallback(() => {\n    if (!playing) {\n      playAll();\n    } else {\n      pauseAll();\n    }\n  })",[1792,1801],"[animate, playing]"]